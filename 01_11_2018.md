# Crypto Basics
	- Numbers
		- As far as a computer, everything is a computer.
		- One file is one number.
		- In crypto, we will be taking numbers and transofrming them to other numbers.
	- Random Numsers
	- Hash Functions
	- Encryption
		- Symmetric
		- Asymmetric
	- Do *NOT* invent crypto.
	- Crypto algorithms can be transformed.
		- That is, if you have a hash algorithm, you can convert it to an encryption algorithm, and vice versa.

# Kerckhoff's Principle
	- "In cryptography, Kerckhoffs's principle (also called Kerckhoffs's desideratum, assumption, axiom, doctrine or law) was stated by Dutch cryptographer Auguste Kerckhoffs in the 19th century: A cryptosystem should be secure even if everything about the system, except the key, is public knowledge."
	- More eyes trivialize all bugs.
	- Say this was war time crypto. If the enemy "captures the machine", then it still does them no good - they don't have the key.
	- Crypto protocols must be open and completely open.
	- "Trust me security" always leads to disaster.
	- No security via obscurity.

# Random #s and Hash Algorithms

## Large Numbers
	- Let's say we want to count all numbers.
	- We use 32 bits.
	- Let's say this takes 1 sec.
	- 33 bits --> 2 sec.
	- 34 bits --> 4 sec
	- 35 bits --> 8 sec.
	...
	- 60 bits --> 36 years
	- 100 bits --> 40 trillion years
	- Exponential growth.
	- For good crypto, the only solution should be to enumerate/guess
	- Hence, we will say that enumeration/guessing is not possible for practical purposes.
	- 128 bit numbers are considered incredibly large and intractable.

## Random Numbers
	- True number generation is very difficult.
	- Computers can't really do it (the community thinks that the intel generator is sketch)
	- To do a true random number, you need entropy (chaos). This exists quite a lot in nature. So we reach out into nature.

## Compute Random Numbers
	- Psuedo random. Functions that take a seed value, computes it, and then recurses the output back into itself until the output is acceptable.
	- You then do statistical analysis show that it all seems to be random.
	- They are good for doing things like science research - you just need somehing statistically random. But for crypto purposes it is useless.

## Hash Functions
	- Takes in number N1 and produces N2. N1 is a variable number of bits. N2 is a fixed number of bits.
	- N2 cannot be reconstructed into N1.
	- Fact of life of a larger domain mapped onto a smaller domain - there WILL be collisions. The problem is when you can handcraft collisions.
	- There are going to be a massive number of collisions (let's just say infinite for the purpose of getting the point across).
	- A hash function is CRYPTO SECURE if it is not possible to handcraft a collision.

# Encryption

## Symmetric

```go
func encrypt(plain, key int) (cipher int) {
		assert len(plain) == len(key) == len(cipher)
}

func decrypt(cipher, key int) (plain int) {
	
}
```

- So called, `symmetric` because both functions use the same `key`.
- Symmetric encryption functions are called "one way (trapdoor) functions".
- Unfortunately, no one has *mathematically proven* the existence of trapdoor functions.

### Building a Symmetric Cipher
- Confusion
	- Making the relationship between the key and ciphertext as complex and involved as possible.
	- One example is permutation, where the permutation table is dependent on the key. But this is not good because we end up with the same number of 0s an 1s. So we also need some...
- Diffusion

	- The redundancy in the statistics of the plaintext is dissipated in the cipher. Done using substitution.

 Network
	^
	|
Substitution
	^
	|
Permutation

Feistel Cipher

## Asymmetric

```go
func encrypt(plain, key1 int) (cipher int) {
		assert len(plain) == len(key) == len(cipher)
}

func decrypt(cipher, key2 int) (plain int) {
	
}
```

- Not *very* different. The difference is that a different, but closely linked, key is used to encrypt a message than is used to decrypt. However, k1 you cannot find k2.
